{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zycNwG-gDCpe"
      },
      "source": [
        "# For Handling Data\n",
        "import pandas as pd\n",
        "\n",
        "# increase the output column width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# For numerical computing\n",
        "import numpy as np\n",
        "\n",
        "# Library for pattern matching\n",
        "import re\n",
        "\n",
        "# for NLP related tasks\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm',disable=[\"tagger\", \"parser\",\"ner\"])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4t1kXzZ9Pr"
      },
      "source": [
        "<font size=5>**Steps to Follow**</font>\n",
        "1. Loading and Exploring Data\n",
        "2. Text Cleaning\n",
        "3. Data Preparation\n",
        "    1. Label Encoding\n",
        "    2. Split Data\n",
        "    3. Feature Engineering using TF-IDF\n",
        "4. Model Building\n",
        "    1. Naive Bayes\n",
        "    2. Logistic Regression\n",
        "    3. Model Building Summary\n",
        "5. Final Sentiment Analysis Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8rRv9giYX2J"
      },
      "source": [
        "# Loading and Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NL8QCLAzKhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323c822d-4b95-4174-b7fe-567edba8cd6f"
      },
      "source": [
        "# mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsmE1o_L8sKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "69d4812b-fd86-4d53-c0f2-7da7aa934f80"
      },
      "source": [
        "# read CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP/tweets (1).csv')\n",
        "\n",
        "#shape of the dataframe\n",
        "print('Shape=>',df.shape)\n",
        "\n",
        "# print first 5 rows\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape=> (14640, 15)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                                                                                             text  \\\n",
              "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
              "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
              "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
              "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
              "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
              "\n",
              "  tweet_coord              tweet_created tweet_location  \\\n",
              "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
              "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
              "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
              "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
              "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
              "\n",
              "                user_timezone  \n",
              "0  Eastern Time (US & Canada)  \n",
              "1  Pacific Time (US & Canada)  \n",
              "2  Central Time (US & Canada)  \n",
              "3  Pacific Time (US & Canada)  \n",
              "4  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b21873b-4f8b-4132-ac76-5d523cc4780a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b21873b-4f8b-4132-ac76-5d523cc4780a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b21873b-4f8b-4132-ac76-5d523cc4780a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b21873b-4f8b-4132-ac76-5d523cc4780a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW6fROJOBHsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95474038-0025-45dc-e43f-dc2f1796f512"
      },
      "source": [
        "# Some sample tweets\n",
        "df['text'].sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9161     @USAirways Hi. I'm in LGA but my luggage is in CLT. Have been told to come back tomorrow to collect. Do you guys want to cover my taxi fare?\n",
              "13159        @AmericanAir follows the Talent PM of #BDSM porn site http://t.co/UQGW6qsFFU. New \"Economy Dungeon\" class coming? http://t.co/pl9Sop5IHu\n",
              "11318    @USAirways is there nothing that can be done online to help? i bought these as a birthday present, just trying to be able to afford a change\n",
              "12797    @AmericanAir lost 3 pieces of our bags, haven't delivered them in 36 hours, lied that they were delivered, and still no refund.  Never again\n",
              "12895                                                                                                 @AmericanAir I've tried...its @USAirways anyway\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHP8lW2nBNtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1316917-80d8-416a-d681-7bd76ebf5e58"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V48ABFS2BamQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f552ce7b-24bb-495e-e76b-d6c79eaa0c3c"
      },
      "source": [
        "# class distribution in percentage\n",
        "df['airline_sentiment'].value_counts(normalize = True)*100"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    62.691257\n",
              "neutral     21.168033\n",
              "positive    16.140710\n",
              "Name: airline_sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryGX7a8YC7KP"
      },
      "source": [
        "# Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpyaEZ7ZCbi4"
      },
      "source": [
        "#define a function for text cleaning\n",
        "def text_cleaner(text):\n",
        "  \n",
        "  #remove user mentions\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text)           \n",
        "  \n",
        "  #remove hashtags\n",
        "  #text = re.sub(r'#[A-Za-z0-9]+','',text)         \n",
        "  \n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+', '', text)  \n",
        "\n",
        "  #convering text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  # fetch only words\n",
        "  text = re.sub(\"[^a-z]+\", \" \", text)\n",
        "\n",
        "  # removing extra spaces\n",
        "  text=re.sub(\"[\\s]+\",\" \",text)\n",
        "  \n",
        "  # creating doc object\n",
        "  doc=nlp(text)\n",
        "\n",
        "  # remove stopwords and lemmatize the text\n",
        "  tokens=[token.lemma_ for token in doc if(token.is_stop==False)]\n",
        "  \n",
        "  #join tokens by space\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwFRBdfyEDR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c1aab2-b7ad-448b-eb6e-bb820fc16a90"
      },
      "source": [
        "# perform text cleaning\n",
        "df['clean_text']= df['text'].apply(text_cleaner)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRZPKAsREL2o"
      },
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = df['clean_text'].values\n",
        "labels = df['airline_sentiment'].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFmdm52REduh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57de30db-132a-437a-8927-542f98914642"
      },
      "source": [
        "# Sample cleaned text\n",
        "text[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['  said', '  plus ve added commercials experience tacky',\n",
              "       '  didn t today mean need trip',\n",
              "       '  s aggressive blast obnoxious entertainment guests faces amp little recourse',\n",
              "       '  s big bad thing',\n",
              "       '  seriously pay flight seats didn t playing s bad thing flying va',\n",
              "       '  yes nearly time fly vx ear worm won t away',\n",
              "       '  missed prime opportunity men hats parody', '  didn t d',\n",
              "       '  amazing arrived hour early good'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsxoIoXBEh5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1f9bdd-b46c-40c5-bcd0-27c14a56429b"
      },
      "source": [
        "# Sample labels\n",
        "labels[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'positive', 'neutral', 'negative', 'negative',\n",
              "       'negative', 'positive', 'neutral', 'positive', 'positive'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI_ffjshaW-U"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baVcHgeJywP0"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TLWk1fCGVB_"
      },
      "source": [
        "#importing label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#define label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a numbers\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osgg4MrwGeZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cd5efe-25c6-46ee-e9a3-7e865370a111"
      },
      "source": [
        "# Sample labels\n",
        "labels[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, 0, 0, 0, 2, 1, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYQr5UOkvtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07825859-61dd-4b7d-bd34-6c4a17db71bd"
      },
      "source": [
        "# Meaning of each label\n",
        "le.inverse_transform([0,1,2])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s1i7gduyyaB"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-8DreSYHQUM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting into train and validation set\n",
        "x_train,x_val,y_train,y_val=train_test_split(text, labels,stratify=labels, test_size=0.2, random_state=0,shuffle=True)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ag4mj1Ho2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70800c35-6b4f-4df4-9c29-970e0bebe78c"
      },
      "source": [
        "print('x_train:',x_train.shape,'y_train:',y_train.shape)\n",
        "print('x_val:',x_val.shape,'y_val:',y_val.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (11712,) y_train: (11712,)\n",
            "x_val: (2928,) y_val: (2928,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yp5tJfiGKoi"
      },
      "source": [
        "## Feature Engineering using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ldb3a6-F4Yb"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nduH1hNrIsg3"
      },
      "source": [
        "# initialize TFIDF\n",
        "word_vectorizer = TfidfVectorizer(max_features=1000)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MINBzLp-IvCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6096fe-450f-4893-ebca-5f26e1b60182"
      },
      "source": [
        "# Fitting Vectorizer on Train set\n",
        "word_vectorizer.fit(x_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_features=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zUWWtupIx1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bb88d2-7980-4de6-c02d-799fcf99642c"
      },
      "source": [
        "# create TF-IDF vectors for Train Set\n",
        "train_word_features = word_vectorizer.transform(x_train)\n",
        "train_word_features"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11712x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 65703 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NMDItaEJN-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec4f6eb-611c-4f6d-9e46-748ac09633cf"
      },
      "source": [
        "# create TF-IDF vectors for Validation Set\n",
        "val_word_features = word_vectorizer.transform(x_val)\n",
        "val_word_features"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2928x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 16550 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p4TbbuuJS7x"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa3PoKl6JmXl"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYhyxfldJRXQ"
      },
      "source": [
        "# Importing for modeling\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEdj-so1Jqip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dda0e68-dec3-4ad8-a7c4-16dcfab2e85e"
      },
      "source": [
        "# Training model\n",
        "nb_model=MultinomialNB().fit(train_word_features,y_train)\n",
        "nb_model"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzMpj555J3ZM"
      },
      "source": [
        "# Make predictions for train set\n",
        "train_pred_nb=nb_model.predict(train_word_features)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IFgZ62jK15l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10885b7-5e76-412b-90cd-d4ae6305811a"
      },
      "source": [
        "train_pred_nb"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exUyd3JZK3Ph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a67f0d-a78d-410b-d50a-280eb39b99d1"
      },
      "source": [
        "# Evaluating on Training Set\n",
        "print(\"F1-score on Train Set:\",f1_score(y_train,train_pred_nb,average=\"weighted\"))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on Train Set: 0.7303326366733179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEiumjqnLah6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0235b4d-f93c-4020-f8ad-8096d37ce8ee"
      },
      "source": [
        "# Make predictions for validation set\n",
        "val_pred_nb=nb_model.predict(val_word_features)\n",
        "\n",
        "# Evaluating on Validation Set\n",
        "print(\"F1-score on Validation Set:\",f1_score(y_val,val_pred_nb,average=\"weighted\"))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on Validation Set: 0.6884471584231738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI-VDut1NzHs"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttdTtqu4Np_s"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgnsHGc1N8_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6046b1-b3f4-4f43-8020-1c35d777e33b"
      },
      "source": [
        "# Training model\n",
        "lr_model=LogisticRegression().fit(train_word_features,y_train)\n",
        "lr_model"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKYJnI7tOCKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f257d953-8769-4a24-efe4-0626f580568a"
      },
      "source": [
        "# Make predictions for train set\n",
        "train_pred_lr=lr_model.predict(train_word_features)\n",
        "train_pred_nb"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeemBVUyOLTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69385c5-47f1-452b-ac00-cb0159428db5"
      },
      "source": [
        "# Evaluating on Training Set\n",
        "print(\"F1-score on Train Set:\",f1_score(y_train,train_pred_lr,average=\"weighted\"))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on Train Set: 0.8074180766755015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CF6IGU0OPu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7307cd-1e0f-4c60-f5a4-1ec5675a70c8"
      },
      "source": [
        "# Make predictions for validation set\n",
        "val_pred_lr=lr_model.predict(val_word_features)\n",
        "\n",
        "# Evaluating on Validation Set\n",
        "print(\"F1-score on Validation Set:\",f1_score(y_val,val_pred_lr,average=\"weighted\"))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on Validation Set: 0.7530566533332674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0X3i_GYOXi1"
      },
      "source": [
        "## Model Building Summary\n",
        "|        Model        | Train Set | Validation Set |\n",
        "|:-------------------:|:---------:|:--------------:|\n",
        "|     Naive Bayes     |   0.7274  |     0.6791     |\n",
        "| Logistic Regression |   0.8089  |     0.7598     |\n",
        "\n",
        "It is evident from the results that Logistic Regression performs better than Naive Bayes on this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE937pt3Vkdh"
      },
      "source": [
        "# Final Sentiment Analysis Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlAQcqW7ObZd"
      },
      "source": [
        "def sentiment_analyzer(tweet):\n",
        "  # Cleaning Tweet\n",
        "  cleaned_tweet=text_cleaner(tweet)\n",
        "\n",
        "  # Feature Engineering\n",
        "  tweet_vector=word_vectorizer.transform([cleaned_tweet])\n",
        "\n",
        "  # Predicting Sentiment\n",
        "  label=lr_model.predict(tweet_vector)\n",
        "\n",
        "  return le.inverse_transform(np.array(label))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwiwbAuJYNW7"
      },
      "source": [
        "<font size=4>**Sample Tweet:**</font>\n",
        "<p>@USAirways flt 419. 2+ hrs Late Flight, baggage + 1 more hr. Now I see they delivered my suitcase wet inside &amp; out. #NotHappy</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIZwLDctZZm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ff9c8d-8763-4384-d57e-6d7765379304"
      },
      "source": [
        "sentiment_analyzer(\"@USAirways flt 419. 2+ hrs Late Flight, baggage + 1 more hr. Now I see they delivered my suitcase wet inside &amp; out. #NotHappy\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRNn6Bvb30iX"
      },
      "source": [],
      "execution_count": 35,
      "outputs": []
    }
  ]
}